
------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n03>
Subject: Job 330387: <numerical_MLP_with_feats_on_log Rg (nm)_20250520> in cluster <Hazel> Done

Job <numerical_MLP_with_feats_on_log Rg (nm)_20250520> was submitted from host <c201n02> by user <sdehgha2> in cluster <Hazel> at Tue May 20 17:18:10 2025
Job was executed on host(s) <6*c203n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue May 20 17:18:10 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue May 20 17:18:10 2025
Terminated at Tue May 20 17:18:19 2025
Results reported at Tue May 20 17:18:19 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 8:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=8GB]"
#BSUB -J "numerical_MLP_with_feats_on_log Rg (nm)_20250520"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "log Rg (nm)"                                   --regressor_type "MLP"                                   --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH' 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4.27 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     8.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   26 sec.
    Turnaround time :                            9 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err> for stderr output of this job.

Average scores:	 r: 0.77±0.08	 r2: 0.57±0.14
Filename: (Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_MLP_hypOFF_Standard
{6: {'fit_time': array([0.30548739, 0.24710989, 0.24414849, 0.24782562, 0.23983169]), 'score_time': array([0.01007795, 0.01003885, 0.00999427, 0.0100317 , 0.00998497]), 'test_pearson_r': array([0.80784317, 0.78612751, 0.67961195, 0.78527721, 0.75043198]), 'test_spearman_r': array([0.83782747, 0.77769003, 0.72249499, 0.7861062 , 0.7572631 ]), 'test_rmse': array([-0.39260747, -0.39616759, -0.4852421 , -0.39829046, -0.36860264]), 'test_mae': array([-0.24317143, -0.27847756, -0.28219564, -0.25321899, -0.2556382 ]), 'test_r2': array([0.64685604, 0.60778049, 0.4023161 , 0.59605142, 0.55485526])}, 13: {'fit_time': array([0.21767831, 0.2039063 , 0.2097857 , 0.20820022, 0.20806742]), 'score_time': array([0.00995827, 0.00961041, 0.00989962, 0.00959945, 0.00962901]), 'test_pearson_r': array([0.66960584, 0.86496534, 0.58221559, 0.74988086, 0.81493366]), 'test_spearman_r': array([0.82196461, 0.89273593, 0.67146305, 0.78696016, 0.8004254 ]), 'test_rmse': array([-0.49174026, -0.3363793 , -0.55584259, -0.42988891, -0.34314229]), 'test_mae': array([-0.29549694, -0.25611194, -0.31800545, -0.28102419, -0.25787603]), 'test_r2': array([0.38530935, 0.73233679, 0.20722149, 0.55421908, 0.63223257])}, 42: {'fit_time': array([0.21661735, 0.16978645, 0.20527983, 0.20778108, 0.20296311]), 'score_time': array([0.00919032, 0.00916052, 0.0088973 , 0.00888395, 0.00894308]), 'test_pearson_r': array([0.81049488, 0.6139718 , 0.73633132, 0.91436193, 0.74075515]), 'test_spearman_r': array([0.80542214, 0.6836286 , 0.74281201, 0.90832248, 0.7314193 ]), 'test_rmse': array([-0.40231745, -0.54139782, -0.34826043, -0.26686625, -0.44718061]), 'test_mae': array([-0.31356933, -0.32891571, -0.24427676, -0.20803741, -0.25128844]), 'test_r2': array([0.6353691 , 0.31973856, 0.51135858, 0.82715273, 0.52028222])}, 69: {'fit_time': array([0.20551205, 0.20782876, 0.21605682, 0.21432304, 0.21736193]), 'score_time': array([0.00901222, 0.00894547, 0.00929856, 0.00924277, 0.00948238]), 'test_pearson_r': array([0.8686223 , 0.70346116, 0.80367434, 0.68132751, 0.84813364]), 'test_spearman_r': array([0.87001537, 0.71420046, 0.83579541, 0.73276837, 0.87121589]), 'test_rmse': array([-0.32407282, -0.4270794 , -0.37378803, -0.4429403 , -0.39143933]), 'test_mae': array([-0.23584305, -0.26803888, -0.25022018, -0.2679122 , -0.2739296 ]), 'test_r2': array([0.72775637, 0.48117138, 0.64401362, 0.44618026, 0.67426893])}, 420: {'fit_time': array([0.20890999, 0.20157766, 0.2045958 , 0.21022534, 0.21414638]), 'score_time': array([0.00888824, 0.00895667, 0.00944495, 0.00917721, 0.00886798]), 'test_pearson_r': array([0.85581089, 0.74790252, 0.83774182, 0.75951984, 0.704924  ]), 'test_spearman_r': array([0.80849074, 0.80309078, 0.80288638, 0.76355952, 0.72579587]), 'test_rmse': array([-0.31407606, -0.41826233, -0.31311793, -0.43764619, -0.46392364]), 'test_mae': array([-0.22689691, -0.29408857, -0.22647111, -0.28709781, -0.28573305]), 'test_r2': array([0.72896558, 0.55171566, 0.69632005, 0.55753472, 0.49627613])}, 1234567890: {'fit_time': array([0.21333885, 0.20537806, 0.21269941, 0.2077992 , 0.21842027]), 'score_time': array([0.00933146, 0.00862455, 0.00855398, 0.00863576, 0.00955153]), 'test_pearson_r': array([0.84483994, 0.88877772, 0.77290055, 0.7491378 , 0.62696303]), 'test_spearman_r': array([0.83048026, 0.86295611, 0.79136783, 0.76659339, 0.68829088]), 'test_rmse': array([-0.30963144, -0.26600254, -0.40741653, -0.42637917, -0.54572845]), 'test_mae': array([-0.21624775, -0.18956021, -0.27824127, -0.28885958, -0.32442526]), 'test_r2': array([0.70931948, 0.78606683, 0.59076415, 0.55312611, 0.37466037])}, 473129: {'fit_time': array([0.20058584, 0.20491171, 0.20742106, 0.20802498, 0.20859432]), 'score_time': array([0.00902343, 0.00909901, 0.00929999, 0.00918937, 0.00922894]), 'test_pearson_r': array([0.60765879, 0.78666651, 0.83677548, 0.85042364, 0.78404976]), 'test_spearman_r': array([0.72113441, 0.81498721, 0.81601025, 0.82595332, 0.76932127]), 'test_rmse': array([-0.53228568, -0.37822361, -0.32668094, -0.34640154, -0.39983194]), 'test_mae': array([-0.29405198, -0.25439802, -0.22668445, -0.25432801, -0.31278754]), 'test_r2': array([0.36013575, 0.55661047, 0.6911337 , 0.71102665, 0.57645848])}, 'pearson_r_avg': 0.7676034117163957, 'pearson_r_stdev': 0.08285711579841884, 'spearman_r_avg': 0.786898548499544, 'spearman_r_stdev': 0.05853923855230339, 'rmse_avg': 0.40139583076231095, 'rmse_stdev': 0.0748258583781406, 'mae_avg': 0.2663748413422705, 'mae_stdev': 0.03320037792580905, 'r2_avg': 0.5727595572635009, 'r2_stdev': 0.138009788847169}
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c203n03>
Subject: Job 330459: <numerical_MLP_with_feats_on_log Rg (nm)_20250520> in cluster <Hazel> Done

Job <numerical_MLP_with_feats_on_log Rg (nm)_20250520> was submitted from host <c201n02> by user <sdehgha2> in cluster <Hazel> at Tue May 20 17:20:52 2025
Job was executed on host(s) <6*c203n03>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue May 20 17:20:52 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue May 20 17:20:52 2025
Terminated at Tue May 20 17:21:13 2025
Results reported at Tue May 20 17:21:13 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input

#BSUB -n 6
#BSUB -W 8:01
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=8GB]"
#BSUB -J "numerical_MLP_with_feats_on_log Rg (nm)_20250520"
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_numerical_only.py --target_features "log Rg (nm)"                                   --regressor_type "MLP"                                   --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH' 

conda deactivate


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   44.30 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     8.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   22 sec.
    Turnaround time :                            21 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250520/numerical_MLP_log Rg (nm)_20250520.err> for stderr output of this job.

