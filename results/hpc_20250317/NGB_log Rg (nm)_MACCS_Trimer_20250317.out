


OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.048743483371937), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 380), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09075966624522726), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 847), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00514844064604902), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09648198199071231), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 266), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.008578279531031132), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.01541708369389806), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.099306068104161), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1934), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00012479442681354922), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06373258564542779), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1124), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00866535867799569), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 355), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09964148082710375), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1985), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.009132948218669307), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09826259769475436), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1881), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00011057713912719824), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09994910690393663), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 907), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001448750238910332), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05432728593271897), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1932), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00011911134316874786), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09946079809719588), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 819), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00011749969653671183), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09677378184475581), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1980), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.005692579417545216), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09951645143061601), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 317), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00012284046803332643), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.021744387861452368), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 670), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09410013441585602), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1992), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.006927516316426565), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05728165121505392), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09834041803261541), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1907), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.005539557180056966), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.045851101339289664), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1874), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00010447317913749431), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09663174637782569), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1018), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00012632121076836257), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 267), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 214), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09552154508615046), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 844), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.008987831788735069), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.019616044573553676), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1188), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0218312971860454), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.009501022052424564), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09972468635399542), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 305), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001445188285952454), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05583714749485724), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 611), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.009471195150623245), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06570034574123047), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1300), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0989489869981765), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 87), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00016107146314202703), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05691087286294366), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 397), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00010407855412003432), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 612), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 473129


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03980140412909695), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 849), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0005495067218457976), ('regressor__regressor__verbose', False)])


Average scores:	 r: 0.94±0.05	 r2: 0.88±0.1
Trimer_scaler
Filename: (MACCS-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Standard
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log Rg (nm)/Trimer_scaler/(MACCS-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Standard_scores.json
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log Rg (nm)/Trimer_scaler/(MACCS-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Standard_predictions.csv
/gpfs_common/share03/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/target_log Rg (nm)/Trimer_scaler/(MACCS-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_NGB_Standard_shape.json
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c205n08>
Subject: Job 379077: <NGB_log Rg (nm)_MACCS_Trimer_20250317> in cluster <Hazel> Done

Job <NGB_log Rg (nm)_MACCS_Trimer_20250317> was submitted from host <c201n05> by user <sdehgha2> in cluster <Hazel> at Tue Mar 18 12:40:36 2025
Job was executed on host(s) <6*c205n08>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Mar 19 07:28:58 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Wed Mar 19 07:28:58 2025
Terminated at Wed Mar 19 13:51:51 2025
Results reported at Wed Mar 19 13:51:51 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 6
#BSUB -W 50:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "NGB_log Rg (nm)_MACCS_Trimer_20250317"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250317/NGB_log Rg (nm)_MACCS_Trimer_20250317.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250317/NGB_log Rg (nm)_MACCS__Trimer_20250317.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../train_structure_numerical.py --target_features "log Rg (nm)"                                       --representation "MACCS"                                       --regressor_type "NGB"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH' 




------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   99550.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.75 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               13.00 GB
    Max Swap :                                   -
    Max Processes :                              30
    Max Threads :                                33
    Run time :                                   22999 sec.
    Turnaround time :                            90675 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250317/NGB_log Rg (nm)_MACCS__Trimer_20250317.err> for stderr output of this job.

