


-------------------------------------------------- 
OOD TEST ON ionic-EG



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06514900817932563), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1988), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.2919870619261817e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06885354575356016), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 334), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1598), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09468464993183168), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 195), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0008352584648170093), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 223), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06104673190303065), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1390), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06875069920455323), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06991692945397764), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 586), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 3.541254600438871e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09803447664035368), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1069), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 6.575543641704289e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.030362057026641638), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.020823697092110016), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1172), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 351), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0974547592526122), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 964), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.580962700615092e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 672), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 289), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 4.1200688201979395e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05818368119157078), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 228), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.2467514100036812e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05384231293674097), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 650), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0009383110033357793), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.053711488979236895), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1985), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.7791912014733428e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06177959093703227), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 547), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.0071504288836015e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.015550790441708956), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1985), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.4144081237995499e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 551), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07352481813242628), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1246), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.390574606467376e-05), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09899263009675877), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1892), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0004749905899576313), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 42


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.02328655868348132), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07393707811947135), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 423), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 581), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 491), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.023304757027629287), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 818), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.054584107726858525), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1020), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.035607657159265525), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 450), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 69


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 486), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.030820944874992214), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 408), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 410), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.059876514165529186), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05913781436124809), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1123), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 2.71006616411378e-05), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.05197078300421611), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 937), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09791587206580206), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1945), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 6.713062990843532e-05), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1498), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03232568013229602), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 583), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1e-06), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 420


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.0995745213196144), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1917), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.3842542767070137e-06), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.03665926811366013), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 843), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09318702357165692), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1964), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 1.3019158463515384e-06), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 574), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.001), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09867973998653726), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 613), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00048110542849172383), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06722043757338259), ('regressor__regressor__minibatch_frac', 1), ('regressor__regressor__n_estimators', 1267), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0009644160953761407), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 1234567890

------------------------------------------------------------
Sender: LSF System <lsfadmin@c022n04>
Subject: Job 295219: <NGB_log Rg (nm)_Mordred_Trimer_EG-Ionic-Based Cluster_20250311> in cluster <Hazel> Exited

Job <NGB_log Rg (nm)_Mordred_Trimer_EG-Ionic-Based Cluster_20250311> was submitted from host <c040n02> by user <sdehgha2> in cluster <Hazel> at Tue Mar 11 19:09:32 2025
Job was executed on host(s) <8*c022n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Wed Mar 12 16:55:05 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Wed Mar 12 16:55:05 2025
Terminated at Thu Mar 13 07:41:44 2025
Results reported at Thu Mar 13 07:41:44 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 72:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "NGB_log Rg (nm)_Mordred_Trimer_EG-Ionic-Based Cluster_20250311"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250311/NGB_log Rg (nm)_Mordred_Trimer_EG-Ionic-Based Cluster_20250311.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250311/NGB_log Rg (nm)_Mordred_Trimer_EG-Ionic-Based Cluster_20250311.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "Mordred"                                       --regressor_type "NGB"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "EG-Ionic-Based Cluster" 



------------------------------------------------------------

Exited with exit code 120.

Resource usage summary:

    CPU time :                                   196417.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.91 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               12.00 GB
    Max Swap :                                   1 GB
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   53207 sec.
    Turnaround time :                            131532 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250311/NGB_log Rg (nm)_Mordred_Trimer_EG-Ionic-Based Cluster_20250311.err> for stderr output of this job.

