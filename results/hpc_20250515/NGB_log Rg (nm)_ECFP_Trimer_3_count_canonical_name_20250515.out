


-------------------------------------------------- 
OOD TEST ON DPPDTT



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06442550373847071), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.014104742475669547), ('regressor__regressor__n_estimators', 1305), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.055935342422725506), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06805294791079948), ('regressor__regressor__n_estimators', 1960), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.006581378382959908), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.023127522957484162), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.017161494865458676), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07201738747731684), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08720529654475748), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.08646479880356304), ('regressor__regressor__n_estimators', 918), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0005053971397801153), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09991915788595498), ('regressor__regressor__n_estimators', 429), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.006589421414282752), ('regressor__regressor__verbose', False)])





-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.1), ('regressor__regressor__n_estimators', 878), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.07693173041362837), ('regressor__regressor__n_estimators', 290), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.004184475212836049), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.051047902014291574), ('regressor__regressor__n_estimators', 485), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.009241621039249212), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.09813692133192081), ('regressor__regressor__n_estimators', 490), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.00691972499929496), ('regressor__regressor__verbose', False)])




Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04868900023997166), ('regressor__regressor__n_estimators', 1310), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.01), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.06274706776431657), ('regressor__regressor__n_estimators', 1058), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.009982280631765959), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13


Best parameters: OrderedDict([('regressor__regressor__learning_rate', 0.04833771724108989), ('regressor__regressor__n_estimators', 2000), ('regressor__regressor__natural_gradient', True), ('regressor__regressor__tol', 0.0001), ('regressor__regressor__verbose', False)])





OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 13

------------------------------------------------------------
Sender: LSF System <lsfadmin@c023n01>
Subject: Job 86623: <NGB_log Rg (nm)_ECFP_Trimer_canonical_name_20250515> in cluster <Hazel> Exited

Job <NGB_log Rg (nm)_ECFP_Trimer_canonical_name_20250515> was submitted from host <c011n02> by user <sdehgha2> in cluster <Hazel> at Fri May 16 03:41:00 2025
Job was executed on host(s) <6*c023n01>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri May 16 05:51:07 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri May 16 05:51:07 2025
Terminated at Fri May 16 09:55:17 2025
Results reported at Fri May 16 09:55:17 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 6
#BSUB -W 70:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "NGB_log Rg (nm)_ECFP_Trimer_canonical_name_20250515"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250515/NGB_log Rg (nm)_ECFP_Trimer_3_count_canonical_name_20250515.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250515/NGB_log Rg (nm)_ECFP_Trimer_3_count_canonical_name_20250515.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "NGB"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "canonical_name" 



------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   66524.00 sec.
    Max Memory :                                 4 GB
    Average Memory :                             3.41 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               12.00 GB
    Max Swap :                                   -
    Max Processes :                              38
    Max Threads :                                41
    Run time :                                   14670 sec.
    Turnaround time :                            22457 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250515/NGB_log Rg (nm)_ECFP_Trimer_3_count_canonical_name_20250515.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON DPPDTT



-------------------------------------------------- 
OPTIMIZING HYPERPARAMETERS FOR REGRESSOR NGB 	SEED: 6

------------------------------------------------------------
Sender: LSF System <lsfadmin@c207n04>
Subject: Job 99239: <NGB_log Rg (nm)_ECFP_Trimer_canonical_name_20250515> in cluster <Hazel> Exited

Job <NGB_log Rg (nm)_ECFP_Trimer_canonical_name_20250515> was submitted from host <c207n05> by user <sdehgha2> in cluster <Hazel> at Fri May 16 10:05:43 2025
Job was executed on host(s) <6*c207n04>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Fri May 16 10:05:45 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Fri May 16 10:05:45 2025
Terminated at Mon May 19 08:10:52 2025
Results reported at Mon May 19 08:10:52 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 6
#BSUB -W 70:05
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "NGB_log Rg (nm)_ECFP_Trimer_canonical_name_20250515"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250515/NGB_log Rg (nm)_ECFP_Trimer_3_count_canonical_name_20250515.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250515/NGB_log Rg (nm)_ECFP_Trimer_3_count_canonical_name_20250515.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "NGB"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "canonical_name" 



------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   1176889.00 sec.
    Max Memory :                                 3 GB
    Average Memory :                             2.10 GB
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               13.00 GB
    Max Swap :                                   -
    Max Processes :                              26
    Max Threads :                                29
    Run time :                                   252323 sec.
    Turnaround time :                            252309 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250515/NGB_log Rg (nm)_ECFP_Trimer_3_count_canonical_name_20250515.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON Fluorene



-------------------------------------------------- 
OOD TEST ON PPV



-------------------------------------------------- 
OOD TEST ON Thiophene



-------------------------------------------------- 
OOD TEST ON Polar
Filename: (MACCS-Xn-Mw-PDI-concentration-temperature-polymer dP-polymer dD-polymer dH-solvent dP-solvent dD-solvent dH)_RF_hypOFF_Standard
{'CO_Fluorene': {'cluster size (%)': 27, 42: {'test_mad': 0.22224482658848072, 'test_ystd': 0.25375642155381584, 'test_mae': 0.5711681866087585, 'test_rmse': 0.6895874213679627, 'test_r2': -0.14664526897784924}, 13: {'test_mad': 0.21162865404390363, 'test_ystd': 0.2535255918134559, 'test_mae': 0.6051336992317274, 'test_rmse': 0.7221208588050432, 'test_r2': -0.2573905771900733}, 'summary_stats': {'test_mad_mean': 0.21693674031619217, 'test_mad_std': 0.0053080862722885425, 'test_ystd_mean': 0.2536410066836359, 'test_ystd_std': 0.00011541487017996399, 'test_mae_mean': 0.588150942920243, 'test_mae_std': 0.016982756311484493, 'test_rmse_mean': 0.7058541400865029, 'test_rmse_std': 0.01626671871854024, 'test_r2_mean': -0.20201792308396127, 'test_r2_std': 0.05537265410611203}}, 'ID_Fluorene': {'cluster size (%)': 25, 42: {'fit_time': array([0.25741506, 0.24130058, 0.25368547, 0.22474504]), 'score_time': array([0.04313946, 0.04597592, 0.04264021, 0.04810309]), 'test_pearson_r': array([0.96926187, 0.9558694 , 0.93144037, 0.89098829]), 'test_spearman_r': array([0.97226412, 0.94274225, 0.91537353, 0.91140035]), 'test_rmse': array([-0.17122992, -0.17513067, -0.20830205, -0.31003226]), 'test_mae': array([-0.11452516, -0.12197787, -0.11712812, -0.12245021]), 'test_r2': array([0.93245068, 0.91352939, 0.86622398, 0.78951077])}, 13: {'fit_time': array([0.30693722, 0.30265284, 0.28789926, 0.3098588 ]), 'score_time': array([0.04347467, 0.04133415, 0.04461217, 0.04204059]), 'test_pearson_r': array([0.92566596, 0.90115814, 0.9364215 , 0.94073212]), 'test_spearman_r': array([0.86976099, 0.93095535, 0.92537707, 0.93007442]), 'test_rmse': array([-0.25819253, -0.29755929, -0.21499617, -0.1972385 ]), 'test_mae': array([-0.15209906, -0.12635879, -0.13134663, -0.12306376]), 'test_r2': array([0.82725121, 0.80618499, 0.87540887, 0.88344289])}, 'summary_stats': {'test_pearson_r_mean': 0.9314422071108859, 'test_pearson_r_std': 0.024303086219128932, 'test_spearman_r_mean': 0.9247435095693317, 'test_spearman_r_std': 0.027245376855056635, 'test_rmse_mean': 0.229085173071517, 'test_rmse_std': 0.04998917681908443, 'test_mae_mean': 0.12611870091263477, 'test_mae_std': 0.01094044005031309, 'test_r2_mean': 0.86175034634176, 'test_r2_std': 0.04724007323080859}}, 'CO_PPV': {'cluster size (%)': 11, 42: {'test_mad': 0.16501977365022932, 'test_ystd': 0.18350982494549137, 'test_mae': 0.4893093901159186, 'test_rmse': 0.6610486587636487, 'test_r2': -2.1635169492414277}, 13: {'test_mad': 0.13054532412987566, 'test_ystd': 0.15129808786786594, 'test_mae': 0.4553610559985194, 'test_rmse': 0.6056182543206643, 'test_r2': -1.6552243544507492}, 'summary_stats': {'test_mad_mean': 0.1477825488900525, 'test_mad_std': 0.017237224760176834, 'test_ystd_mean': 0.16740395640667866, 'test_ystd_std': 0.016105868538812712, 'test_mae_mean': 0.472335223057219, 'test_mae_std': 0.016974167058699613, 'test_rmse_mean': 0.6333334565421564, 'test_rmse_std': 0.027715202221492208, 'test_r2_mean': -1.9093706518460885, 'test_r2_std': 0.2541462973953392}}, 'ID_PPV': {'cluster size (%)': 11, 42: {'fit_time': array([0.34249258, 0.30867076, 0.36686301, 0.37476254, 0.4023459 ,
       0.37030816, 0.33228898, 0.42102408, 0.34287071]), 'score_time': array([0.0507133 , 0.04138541, 0.04716563, 0.04321074, 0.04571819,
       0.04802227, 0.03708673, 0.04254985, 0.04331255]), 'test_pearson_r': array([0.97545908, 0.97125646, 0.97252279, 0.96743418, 0.97584738,
       0.93665084, 0.95971028, 0.93487726, 0.83068857]), 'test_spearman_r': array([0.97634314, 0.9651435 , 0.93730756, 0.95812808, 0.98115532,
       0.86485161, 0.95750709, 0.89209019, 0.86406578]), 'test_rmse': array([-0.14272647, -0.18971469, -0.14808513, -0.15834257, -0.11457094,
       -0.20544814, -0.18193801, -0.24492051, -0.36912153]), 'test_mae': array([-0.08542071, -0.11936833, -0.09963995, -0.10748863, -0.07955618,
       -0.12079014, -0.10218305, -0.12290779, -0.1225185 ]), 'test_r2': array([0.94805195, 0.93317832, 0.93450884, 0.93350039, 0.94950462,
       0.87702606, 0.91616896, 0.86968439, 0.67057571])}, 13: {'fit_time': array([0.33917451, 0.36033511, 0.28709316, 0.38031745, 0.37868643,
       0.36762333, 0.36259079, 0.37001395, 0.42245245]), 'score_time': array([0.07263446, 0.04790092, 0.10068679, 0.04421663, 0.04677343,
       0.04578757, 0.04632807, 0.04361892, 0.03947639]), 'test_pearson_r': array([0.98582338, 0.98161149, 0.95612362, 0.83633582, 0.9319941 ,
       0.94445116, 0.95959381, 0.96897535, 0.93588112]), 'test_spearman_r': array([0.96215956, 0.96351987, 0.91280788, 0.8683011 , 0.93198631,
       0.90197044, 0.96312828, 0.969896  , 0.91621043]), 'test_rmse': array([-0.09967628, -0.13300516, -0.19778516, -0.41085308, -0.20800128,
       -0.1906703 , -0.18107253, -0.16111857, -0.21266005]), 'test_mae': array([-0.07453983, -0.08823518, -0.12538548, -0.17869886, -0.1076001 ,
       -0.11745783, -0.09088207, -0.09396122, -0.13794496]), 'test_r2': array([0.97130907, 0.95711371, 0.90217954, 0.68371647, 0.86673595,
       0.88996682, 0.91978874, 0.93223534, 0.8441647 ])}, 'summary_stats': {'test_pearson_r_mean': 0.9458464835417646, 'test_pearson_r_std': 0.04298015173122252, 'test_spearman_r_mean': 0.9325873420194473, 'test_spearman_r_std': 0.03904285983702523, 'test_rmse_mean': 0.19720613335804227, 'test_rmse_std': 0.07715369371314489, 'test_mae_mean': 0.10969882435684113, 'test_mae_std': 0.024018521706707454, 'test_r2_mean': 0.8888560885177478, 'test_r2_std': 0.0820459836572952}}, 'CO_Thiophene': {'cluster size (%)': 62, 42: {'test_mad': 0.2608404143788921, 'test_ystd': 0.30930606298395796, 'test_mae': 0.45415328126205373, 'test_rmse': 0.5581534204347883, 'test_r2': -0.014801193932892254}, 13: {'test_mad': 0.24833037217257922, 'test_ystd': 0.2950406505455196, 'test_mae': 0.46883340548402297, 'test_rmse': 0.5707734569698969, 'test_r2': -0.06120998053050308}, 'summary_stats': {'test_mad_mean': 0.25458539327573565, 'test_mad_std': 0.006255021103156441, 'test_ystd_mean': 0.3021733567647388, 'test_ystd_std': 0.007132706219219187, 'test_mae_mean': 0.4614933433730384, 'test_mae_std': 0.007340062110984619, 'test_rmse_mean': 0.5644634387023426, 'test_rmse_std': 0.006310018267554285, 'test_r2_mean': -0.03800558723169767, 'test_r2_std': 0.023204393298805415}}, 'ID_Thiophene': {'cluster size (%)': 50, 42: {'fit_time': array([0.27715397, 0.26014829]), 'score_time': array([0.05889654, 0.052912  ]), 'test_pearson_r': array([0.84339094, 0.88879248]), 'test_spearman_r': array([0.8960558 , 0.89231684]), 'test_rmse': array([-0.33915166, -0.29476959]), 'test_mae': array([-0.17108888, -0.16208894]), 'test_r2': array([0.70942706, 0.7772365 ])}, 13: {'fit_time': array([0.28151441, 0.30259323]), 'score_time': array([0.06257272, 0.05512118]), 'test_pearson_r': array([0.88132072, 0.84722102]), 'test_spearman_r': array([0.87002844, 0.83730751]), 'test_rmse': array([-0.32607277, -0.32290304]), 'test_mae': array([-0.18723443, -0.18234587]), 'test_r2': array([0.75428795, 0.70439265])}, 'summary_stats': {'test_pearson_r_mean': 0.8651812899408537, 'test_pearson_r_std': 0.020095769359636976, 'test_spearman_r_mean': 0.8739271476437859, 'test_spearman_r_std': 0.02336694020134006, 'test_rmse_mean': 0.3207242653918358, 'test_rmse_std': 0.016175349794796488, 'test_mae_mean': 0.17568953269778975, 'test_mae_std': 0.00979456084073188, 'test_r2_mean': 0.736336039506535, 'test_r2_std': 0.030576102861376426}}, 'CO_Polar': {'cluster size (%)': 6, 42: {'test_mad': 0.32875909352799493, 'test_ystd': 0.33299169096223497, 'test_mae': 0.7726524756419717, 'test_rmse': 0.8882750441990179, 'test_r2': 0.04623926960511471}, 13: {'test_mad': 0.2909995512244871, 'test_ystd': 0.29682687883576925, 'test_mae': 0.8122267842435035, 'test_rmse': 0.9162024305780585, 'test_r2': -0.014676014485646593}, 'summary_stats': {'test_mad_mean': 0.30987932237624105, 'test_mad_std': 0.018879771151753905, 'test_ystd_mean': 0.3149092848990021, 'test_ystd_std': 0.01808240606323286, 'test_mae_mean': 0.7924396299427376, 'test_mae_std': 0.019787154300765886, 'test_rmse_mean': 0.9022387373885382, 'test_rmse_std': 0.013963693189520288, 'test_r2_mean': 0.015781627559734057, 'test_r2_std': 0.03045764204538065}}, 'ID_Polar': {'cluster size (%)': 6, 42: {'fit_time': array([0.52454019, 0.61136508, 0.76134443, 0.7476902 , 0.74596715,
       0.45093822, 0.71032166, 0.57981467, 0.72756124, 0.80342555,
       0.57966685, 0.73285007, 0.63800216, 0.50661373, 0.75600052,
       0.57885122]), 'score_time': array([0.13856339, 0.04340386, 0.05251861, 0.04884791, 0.05339289,
       0.12541509, 0.06163168, 0.0350039 , 0.04679704, 0.04330754,
       0.04851437, 0.04726386, 0.0330193 , 0.12965655, 0.04308414,
       0.09703755]), 'test_pearson_r': array([0.97187967, 0.99292362, 0.94391969, 0.95683699, 0.9891185 ,
       0.9789882 , 0.93913551, 0.98319804, 0.95254631, 0.93143966,
       0.98265211, 0.9409284 , 0.95281813, 0.92493847, 0.63301215,
       0.99372522]), 'test_spearman_r': array([0.97731471, 0.97486223, 0.93627451, 0.90294118, 0.95588235,
       0.95588235, 0.95      , 0.99043441, 0.94411765, 0.87858743,
       0.96764706, 0.95882353, 0.95511431, 0.90332718, 0.71764706,
       0.98232802]), 'test_rmse': array([-0.16920787, -0.08057073, -0.23134354, -0.17442804, -0.10777844,
       -0.13276356, -0.19154292, -0.10262407, -0.16060651, -0.22972149,
       -0.12836916, -0.19768661, -0.21678585, -0.26045446, -0.52523012,
       -0.08192105]), 'test_mae': array([-0.09995418, -0.05548602, -0.13484899, -0.11804456, -0.07972489,
       -0.10065513, -0.13744826, -0.07332584, -0.0937476 , -0.13309594,
       -0.08914779, -0.11338822, -0.09036222, -0.13376249, -0.17919009,
       -0.05598079]), 'test_r2': array([0.93324787, 0.98554734, 0.86737884, 0.90601061, 0.97460513,
       0.95600432, 0.87416897, 0.9563227 , 0.8964042 , 0.8338653 ,
       0.95696673, 0.87932458, 0.90310517, 0.84294695, 0.29512996,
       0.98446139])}, 13: {'fit_time': array([0.49514222, 0.69223833, 0.61267686, 0.64814687, 0.6225183 ,
       0.6449275 , 0.5920558 , 0.66449714, 0.54947233, 0.67748594,
       0.6532886 , 0.66416454, 0.63991451, 0.64401221, 0.53207445,
       0.58299828]), 'score_time': array([0.22884917, 0.04857111, 0.0725162 , 0.08145022, 0.09085059,
       0.07035017, 0.07876325, 0.05167747, 0.06197882, 0.05991387,
       0.06215787, 0.05856037, 0.05506802, 0.04356027, 0.05912471,
       0.04569268]), 'test_pearson_r': array([0.99024432, 0.98263903, 0.98822493, 0.99228674, 0.92364009,
       0.96087456, 0.70989303, 0.99617747, 0.89565267, 0.98207967,
       0.7950017 , 0.99300642, 0.99340857, 0.92339532, 0.98724359,
       0.91193175]), 'test_spearman_r': array([0.94297994, 0.91355014, 0.96560488, 0.94628429, 0.91176471,
       0.92862424, 0.73235294, 0.99705882, 0.89919082, 0.94117647,
       0.8550407 , 0.99117647, 0.99705882, 0.87941176, 0.99558282,
       0.85      ]), 'test_rmse': array([-0.0723164 , -0.13506517, -0.0922303 , -0.11638948, -0.23727848,
       -0.19596822, -0.51620863, -0.0726028 , -0.21662926, -0.11327893,
       -0.37612001, -0.08812611, -0.07277602, -0.24397531, -0.11299957,
       -0.23969644]), 'test_mae': array([-0.04897859, -0.10707585, -0.06881909, -0.08081859, -0.14014171,
       -0.12504432, -0.21706542, -0.04947403, -0.13182275, -0.08990465,
       -0.23488393, -0.06711809, -0.05403942, -0.14333073, -0.06461289,
       -0.16009712]), 'test_r2': array([0.98030533, 0.95637128, 0.97493712, 0.97143036, 0.8482859 ,
       0.91870198, 0.44481774, 0.98987268, 0.79289679, 0.95847048,
       0.61091106, 0.98318717, 0.98361241, 0.83127153, 0.96745329,
       0.77132335])}, 'summary_stats': {'test_pearson_r_mean': 0.9404300158602317, 'test_pearson_r_std': 0.08089532626296718, 'test_spearman_r_mean': 0.9280638071455919, 'test_spearman_r_std': 0.06581702384219658, 'test_rmse_mean': 0.18414673589108693, 'test_rmse_std': 0.11151711956999957, 'test_mae_mean': 0.10848094353327992, 'test_mae_std': 0.04553529885302597, 'test_r2_mean': 0.8759168285815357, 'test_r2_std': 0.15458339859783723}}, 'overall data shape': {'targets_shape': (259, 1), 'training_features_shape': (259, 178)}}
Done Saving scores!

------------------------------------------------------------
Sender: LSF System <lsfadmin@c201n09>
Subject: Job 309302: <NGB_log Rg (nm)_ECFP_Trimer_canonical_name_20250515> in cluster <Hazel> Done

Job <NGB_log Rg (nm)_ECFP_Trimer_canonical_name_20250515> was submitted from host <c201n09> by user <sdehgha2> in cluster <Hazel> at Tue May 20 07:42:20 2025
Job was executed on host(s) <8*c201n09>, in queue <single_chassis>, as user <sdehgha2> in cluster <Hazel> at Tue May 20 07:43:19 2025
</home/sdehgha2> was used as the home directory.
</share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/code_/training/hpc_submit_training_Rh> was used as the working directory.
Started at Tue May 20 07:43:19 2025
Terminated at Tue May 20 07:43:48 2025
Results reported at Tue May 20 07:43:48 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input



#BSUB -n 8
#BSUB -W 30:30
#BSUB -R span[hosts=1]
#BSUB -R "rusage[mem=16GB]"
#BSUB -J "NGB_log Rg (nm)_ECFP_Trimer_canonical_name_20250515"  
#BSUB -o "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250515/NGB_log Rg (nm)_ECFP_Trimer_3_count_canonical_name_20250515.out"
#BSUB -e "/share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250515/NGB_log Rg (nm)_ECFP_Trimer_3_count_canonical_name_20250515.err"

source ~/.bashrc
conda activate /usr/local/usrapps/ddomlab/sdehgha2/pls-dataset-env
python ../make_ood_prediction.py --target_features "log Rg (nm)"                                       --representation "ECFP"                                       --regressor_type "NGB"                                       --radius "3"                                       --vector "count"                                       --oligomer_representation "Trimer"                                       --numerical_feats 'Xn' 'Mw (g/mol)' 'PDI' 'Concentration (mg/ml)' 'Temperature SANS/SLS/DLS/SEC (K)' "polymer dP" "polymer dD" "polymer dH" 'solvent dP' 'solvent dD' 'solvent dH'                                       --clustering_method "canonical_name" 



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   103.00 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     16.00 GB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   55 sec.
    Turnaround time :                            88 sec.

The output (if any) is above this job summary.



PS:

Read file </share/ddomlab/sdehgha2/working-space/main/P1_pls-dataset/pls-dataset-space/PLS-Dataset/results/hpc_20250515/NGB_log Rg (nm)_ECFP_Trimer_3_count_canonical_name_20250515.err> for stderr output of this job.




-------------------------------------------------- 
OOD TEST ON DPPDTT
